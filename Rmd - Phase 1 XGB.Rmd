---
title: "Phase 1 XGB"
output: pdf_document
date: '2022-06-14'
---

# =================== PHASE 1 XGBoost ===================

## Training set optimisation

### Cross-validation

```{r}
CVerrors <- numeric(10)
NROUNDS <- integer(10)
```

```{r}
# set parameter values that will be constant 
eta <- 0.01
```

```{r}
registerDoParallel()
```

```{r}
# use cv to select the correct hyperparameters
# gamma, lambda, subsample, colsample_bytree and min_child_weight are default values

# eta = set to 0.01
# smaller values of shrinkage (almost) always give improved predictive performance
# for 3,000 to 10,000 iterations with shrinkage rates between 0.01 and 0.001.

# tuning for only tree depth and number of rounds
for(depth in 1L:10L){ # tree depth 
  mCV <- xgb.cv(data = Xtrain, 
                label = Ytrain, 
                params = list(eta=eta, # shrinkage parameter (learning rate) 
                              max_depth=depth), # max number of tree splits/variables in one tree 
                nrounds=10000000, # max number of trees 
                objective = "binary:logistic",
                eval_metric = "logloss",  # evaluation metric
                nfold = 10, # k-folds 
                early_stopping_rounds = 50, # algorithm stops if no more improvement
                verbose = 0) # silent 
  # calculate CVerror and number of rounds for each depth 
  CVerrors[depth] <- min(mCV$evaluation_log$test_logloss_mean) 
  NROUNDS[depth] <- mCV$best_iteration
}
```

```{r}
# plot 
# training vs test errors
cv_df <- data.frame(TRAINING_ERROR = mCV$evaluation_log$train_logloss_mean,
                    VALIDATION_ERROR = mCV$evaluation_log$test_logloss_mean, 
                    ITERATION = mCV$evaluation_log$iter) %>%
  mutate(MIN = VALIDATION_ERROR == min(VALIDATION_ERROR))


cv_df_longer <- pivot_longer(data = cv_df, 
                              cols = c(TRAINING_ERROR, VALIDATION_ERROR), 
                              names_to = "ERROR_TYPE",
                              values_to = "ERROR")

g_train_val_error <- ggplot(cv_df_longer, aes(x = ITERATION)) +        # Check for overfitting
  geom_line(aes(y = ERROR, group = ERROR_TYPE, colour = ERROR_TYPE)) +
  geom_vline(xintercept = mCV$best_iteration, colour = " dark blue") +

  labs(
    x = "CV Iterations",
    y = "Log-loss validation error") +
  scale_colour_discrete(name="Error type", 
                        labels=c("Training error", "Validation error")) +
  theme_classic() +
  theme(legend.position="bottom")

g_train_val_error
```

```{r}
# select tuning parameters based on best iteration 
best_d <- which.min(CVerrors) # choose depth for lowest cv error
best_nrounds <- NROUNDS[best_d] # choose nrounds for lowest cv error
```

### Training the model 

```{r}
# Build the best model based on the cross validation error 
best_model <- xgboost(data = Xtrain,
             label = Ytrain,
             params = list(eta=eta, 
                           max_depth=best_d), #tuned
             nrounds=ceiling(best_nrounds*1.1), # tuned
             objective = "binary:logistic",
             eval_metric = "logloss",
             verbose = 0)
```

### Tune classification threshold on the training set

```{r}
# predictions on training set 
training_predictions <- predict(best_model, Xtrain)
summary(training_predictions)
```

```{r}
# Precision 
precision_score <- sapply(seq(0.01, 0.99, by=.01), function(thresh) Precision(Ytrain, 
                    ifelse(training_predictions >= thresh, 1, 0), positive = 1))

# Recall
recall_score <- sapply(seq(0.01, 0.99, by=.01), function(thresh) Recall(Ytrain, 
                    ifelse(training_predictions >= thresh, 1, 0), positive = 1))
```

```{r}
# F1
f1_scores <- sapply(seq(0.01, 0.99, by=.01), function(thresh) F1_Score(Ytrain, 
                    ifelse(training_predictions >= thresh, 1, 0), positive = 1))
 
which.max(f1_scores) 
```

```{r}
# F2
f_beta_scores2 <- sapply(seq(0.01, 0.99, by=.01), function(thresh) FBeta_Score(Ytrain, 
                    ifelse(training_predictions >= thresh, 1, 0), 
                    positive = 1, beta = 2))
 
which.max(f_beta_scores2)
```

```{r}
# F0.5
f_beta_scores0.5 <- sapply(seq(0.01, 0.99, by=.01), function(thresh) FBeta_Score(Ytrain, 
                    ifelse(training_predictions >= thresh, 1, 0), 
                    positive = 1, beta = 0.5))
 
which.max(f_beta_scores0.5)
```

```{r}
# plot every threshold for training set
# in one data frame
f_scores.df <- as.data.frame(precision_score)
f_scores.df$Recall <- recall_score
f_scores.df$F1 <- f1_scores
f_scores.df$F2 <- f_beta_scores2
f_scores.df$F0.5 <- f_beta_scores0.5
f_scores.df$threshold <- seq(0.01, 0.99, by=.01)
f_scores.df <- f_scores.df %>% 
  rename(
    Precision = precision_score
    )
```

```{r}
f_scores.melt <- melt(data = f_scores.df, id.vars = "threshold")

p1 <- ggplot(data = f_scores.melt, aes(x = threshold, y = value, colour = variable)) + 
  geom_line() +
  theme_classic() +
  ylab("Value") + xlab("Classification threshold")+
  theme(legend.title=element_text(size=20),
        legend.text =element_text(size=15),
        axis.title = element_text(size=20),
        axis.text = element_text(size=15)) 

update_labels(p1, list(colour="Metric"))
  
```

#### Find F-scores on training set 

```{r}
Precision(Ytrain, 
          ifelse(training_predictions >= (which.max(f_beta_scores2)/100), 1, 0), 
          positive = "1")
Recall(Ytrain, 
       ifelse(training_predictions >= (which.max(f_beta_scores2)/100), 1, 0), 
       positive = "1")
F1_Score(Ytrain, 
         ifelse(training_predictions >= (which.max(f_beta_scores2)/100), 1, 0), 
         positive = "1")
FBeta_Score(Ytrain, 
            ifelse(training_predictions >= (which.max(f_beta_scores2)/100), 1, 0), 
            positive = "1", beta=2)
```

#### Set classification threshold

```{r}
# based on maximised F2
threshold <- which.max(f_beta_scores2)/100
```

## Test set performance

### Predictions on test set 

```{r}
# Predict based on the best model 
out <- predict(best_model, newdata = Xtest)

# collecting the predictions in a dataframe 
# prediction are the probability of the lead converting into a qualified opportunity (lead conversion rate)
df.out <- data.frame(id=as.integer(rownames(Xtest)),Prediction_Score=out)

# summary statistics of the predictions
summary(df.out$Prediction_Score)

# output = b1
```

### Evaluate performance on test set

#### AUC-ROC

```{r}
# plot roc curve 
par(pty = "s")
roc_object_XGB <- roc(Ytest, df.out$Prediction_Score, plot = TRUE, print.auc=TRUE,
                       col="brown2")
```

#### Confusion matrix, recall, precision, F2

```{r}
# get binary predictions 
XGB_bin_pred <- ifelse(df.out$Prediction_Score > threshold, 1, 0)
```

```{r}
# get confusion matrix 
confusionMatrix(factor(XGB_bin_pred), factor(Ytest), positive = "1")
```

```{r}
# confusion matrix in percentages
prop.table(caret::confusionMatrix(factor(XGB_bin_pred), factor(Ytest), positive="1")$table)
```

```{r}
# get precision, recall and F2 beta score on test set
Precision(y_pred=XGB_bin_pred, y_true=Ytest, positive="1")
Recall(y_pred=XGB_bin_pred, y_true=Ytest, positive="1")
F1_Score(y_pred=XGB_bin_pred, y_true=Ytest, positive="1")
FBeta_Score(y_pred=XGB_bin_pred, y_true=Ytest, positive="1", beta=2)
```

## Feature importance analyses

### All features 

```{r}
# Variable importance
feature_importance <- xgb.importance(
  feature_names = colnames(Xtrain), model = best_model) # extracts all important features

head(feature_importance)

xgb.ggplot.importance(feature_importance[1:5])+ # plot for 5 most important features
  theme_classic() 
```

### Combinations of feature types

```{r}
# 1-97: online behavior 
# 98-131: demographic 
# 132-176: online behavior 
# 177-201: demographic 
# 202-478: platform data
# 497-558: online behavior 

# only considering demographics
Xtrain2 <-Xtrain[,c(98:131,177:201)]
Xtest2 <- Xtest[,c(98:131,177:201)]

# only considering online behavior
Xtrain3 <-Xtrain[,c(1:97,132:176,497:558)]
Xtest3 <- Xtest[,c(1:97,132:176,497:558)]

# only considering platform events
Xtrain4 <-Xtrain[,c(202:478)]
Xtest4 <- Xtest[,c(202:478)]

# only considering demographics+online behavior
Xtrain5 <-Xtrain[,-c(202:478)]
Xtest5 <- Xtest[,-c(202:478)]

# only considering online behavior+platforms events
Xtrain6 <-Xtrain[,-c(98:131,177:201)]
Xtest6 <- Xtest[,-c(98:131,177:201)]

# only considering demographics+platforms events
Xtrain7 <-Xtrain[,-c(1:97,132:176,497:558)]
Xtest7 <- Xtest[,-c(1:97,132:176,497:558)]
```

#### Only demographic

```{r}
CVerrors2 <- numeric(10)
NROUNDS2 <- integer(10)
```

```{r}
# set parameter values that will be constant 
eta <- 0.01
```

```{r}
registerDoParallel()
```

```{r}
# use cv to select the correct hyperparameters
# gamma, lambda, subsample, colsample_bytree and min_child_weight are default values

# eta = set to 0.01
# smaller values of shrinkage (almost) always give improved predictive performance
# for 3,000 to 10,000 iterations with shrinkage rates between 0.01 and 0.001.

# tuning for only tree depth and number of rounds
for(depth in 1L:10L){ # tree depth 
  mCV.2 <- xgb.cv(data = Xtrain2, 
                label = Ytrain, 
                params = list(eta=eta, # shrinkage parameter (learning rate) 
                              max_depth=depth), # max number of tree splits/variables in one tree 
                nrounds=10000000, # max number of trees 
                objective = "binary:logistic",
                eval_metric = "logloss",  # evaluation metric
                nfold = 10, # k-folds 
                early_stopping_rounds = 50, # algorithm stops if no more improvement
                verbose = 0) # silent 
  # calculate CVerror and number of rounds for each depth 
  CVerrors2[depth] <- min(mCV.2$evaluation_log$test_logloss_mean) 
  NROUNDS2[depth] <- mCV.2$best_iteration
}
```


```{r}
# select tuning parameters based on best iteration 
best_d2 <- which.min(CVerrors2) # choose depth for lowest cv error
best_nrounds2 <- NROUNDS2[best_d2] # choose nrounds for lowest cv error
```

##### Training the model 

```{r}
# Build the best model based on the cross validation error 
best_model.2 <- xgboost(data = Xtrain2,
             label = Ytrain,
             params = list(eta=eta, 
                           max_depth=best_d2), #tuned
             nrounds=ceiling(best_nrounds2*1.1), # tuned
             objective = "binary:logistic",
             eval_metric = "logloss",
             verbose = 0)
```

```{r}
# Predict based on the best model 
out.2 <- predict(best_model.2, newdata = Xtest2)

# collecting the predictions in a dataframe 
# prediction are the probability of the lead converting into a qualified opportunity (lead conversion rate)
df.out.2 <- data.frame(id=as.integer(rownames(Xtest2)),Prediction_Score2=out.2)
```

#### Only behaviour

```{r}
CVerrors3 <- numeric(10)
NROUNDS3 <- integer(10)
```

```{r}
# set parameter values that will be constant 
eta <- 0.01
```

```{r}
registerDoParallel()
```

```{r}
# use cv to select the correct hyperparameters
# gamma, lambda, subsample, colsample_bytree and min_child_weight are default values

# eta = set to 0.01
# smaller values of shrinkage (almost) always give improved predictive performance
# for 3,000 to 10,000 iterations with shrinkage rates between 0.01 and 0.001.

# tuning for only tree depth and number of rounds
for(depth in 1L:10L){ # tree depth 
  mCV.3 <- xgb.cv(data = Xtrain3, 
                label = Ytrain, 
                params = list(eta=eta, # shrinkage parameter (learning rate) 
                              max_depth=depth), # max number of tree splits/variables in one tree 
                nrounds=10000000, # max number of trees 
                objective = "binary:logistic",
                eval_metric = "logloss",  # evaluation metric
                nfold = 10, # k-folds 
                early_stopping_rounds = 50, # algorithm stops if no more improvement
                verbose = 0) # silent 
  # calculate CVerror and number of rounds for each depth 
  CVerrors3[depth] <- min(mCV.3$evaluation_log$test_logloss_mean) 
  NROUNDS3[depth] <- mCV.3$best_iteration
}
```


```{r}
# select tuning parameters based on best iteration 
best_d3 <- which.min(CVerrors3) # choose depth for lowest cv error
best_nrounds3 <- NROUNDS3[best_d3] # choose nrounds for lowest cv error
```

##### Training the model 

```{r}
# Build the best model based on the cross validation error 
best_model.3 <- xgboost(data = Xtrain3,
             label = Ytrain,
             params = list(eta=eta, 
                           max_depth=best_d3), #tuned
             nrounds=ceiling(best_nrounds3*1.1), # tuned
             objective = "binary:logistic",
             eval_metric = "logloss",
             verbose = 0)
```

```{r}
# Predict based on the best model 
out.3 <- predict(best_model.3, newdata = Xtest3)

# collecting the predictions in a dataframe 
# prediction are the probability of the lead converting into a qualified opportunity (lead conversion rate)
df.out.3 <- data.frame(id=as.integer(rownames(Xtest3)),Prediction_Score3=out.3)
```


#### Only platform data 

```{r}
CVerrors4 <- numeric(10)
NROUNDS4 <- integer(10)
```

```{r}
# set parameter values that will be constant 
eta <- 0.01
```

```{r}
registerDoParallel()
```

```{r}
# use cv to select the correct hyperparameters
# gamma, lambda, subsample, colsample_bytree and min_child_weight are default values

# eta = set to 0.01
# smaller values of shrinkage (almost) always give improved predictive performance
# for 3,000 to 10,000 iterations with shrinkage rates between 0.01 and 0.001.

# tuning for only tree depth and number of rounds
for(depth in 1L:10L){ # tree depth 
  mCV.4 <- xgb.cv(data = Xtrain4, 
                label = Ytrain, 
                params = list(eta=eta, # shrinkage parameter (learning rate) 
                              max_depth=depth), # max number of tree splits/variables in one tree 
                nrounds=10000000, # max number of trees 
                objective = "binary:logistic",
                eval_metric = "logloss",  # evaluation metric
                nfold = 10, # k-folds 
                early_stopping_rounds = 50, # algorithm stops if no more improvement
                verbose = 0) # silent 
  # calculate CVerror and number of rounds for each depth 
  CVerrors4[depth] <- min(mCV.4$evaluation_log$test_logloss_mean) 
  NROUNDS4[depth] <- mCV.4$best_iteration
}
```


```{r}
# select tuning parameters based on best iteration 
best_d4 <- which.min(CVerrors4) # choose depth for lowest cv error
best_nrounds4 <- NROUNDS4[best_d4] # choose nrounds for lowest cv error
```

##### Training the model 

```{r}
# Build the best model based on the cross validation error 
best_model.4 <- xgboost(data = Xtrain4,
             label = Ytrain,
             params = list(eta=eta, 
                           max_depth=best_d4), #tuned
             nrounds=ceiling(best_nrounds4*1.1), # tuned
             objective = "binary:logistic",
             eval_metric = "logloss",
             verbose = 0)
```

```{r}
# Predict based on the best model 
out.4 <- predict(best_model.4, newdata = Xtest4)

# collecting the predictions in a dataframe 
# prediction are the probability of the lead converting into a qualified opportunity (lead conversion rate)
df.out.4 <- data.frame(id=as.integer(rownames(Xtest4)),Prediction_Score4=out.4)
```

#### Demographics+online activity

```{r}
CVerrors5 <- numeric(10)
NROUNDS5 <- integer(10)
```

```{r}
# set parameter values that will be constant 
eta <- 0.01
```

```{r}
registerDoParallel()
```

```{r}
# use cv to select the correct hyperparameters
# gamma, lambda, subsample, colsample_bytree and min_child_weight are default values

# eta = set to 0.01
# smaller values of shrinkage (almost) always give improved predictive performance
# for 3,000 to 10,000 iterations with shrinkage rates between 0.01 and 0.001.

# tuning for only tree depth and number of rounds
for(depth in 1L:10L){ # tree depth 
  mCV.5 <- xgb.cv(data = Xtrain5, 
                label = Ytrain, 
                params = list(eta=eta, # shrinkage parameter (learning rate) 
                              max_depth=depth), # max number of tree splits/variables in one tree 
                nrounds=10000000, # max number of trees 
                objective = "binary:logistic",
                eval_metric = "logloss",  # evaluation metric
                nfold = 10, # k-folds 
                early_stopping_rounds = 50, # algorithm stops if no more improvement
                verbose = 0) # silent 
  # calculate CVerror and number of rounds for each depth 
  CVerrors5[depth] <- min(mCV.5$evaluation_log$test_logloss_mean) 
  NROUNDS5[depth] <- mCV.5$best_iteration
}
```


```{r}
# select tuning parameters based on best iteration 
best_d5 <- which.min(CVerrors5) # choose depth for lowest cv error
best_nrounds5 <- NROUNDS5[best_d5] # choose nrounds for lowest cv error
```

##### Training the model 

```{r}
# Build the best model based on the cross validation error 
best_model.5 <- xgboost(data = Xtrain5,
             label = Ytrain,
             params = list(eta=eta, 
                           max_depth=best_d5), #tuned
             nrounds=ceiling(best_nrounds5*1.1), # tuned
             objective = "binary:logistic",
             eval_metric = "logloss",
             verbose = 0)
```

```{r}
# Predict based on the best model 
out.5 <- predict(best_model.5, newdata = Xtest5)

# collecting the predictions in a dataframe 
# prediction are the probability of the lead converting into a qualified opportunity (lead conversion rate)
df.out.5 <- data.frame(id=as.integer(rownames(Xtest5)),Prediction_Score5=out.5)
```

#### Online behavior+platforms events

```{r}
CVerrors6 <- numeric(10)
NROUNDS6 <- integer(10)
```

```{r}
# set parameter values that will be constant 
eta <- 0.01
```

```{r}
registerDoParallel()
```

```{r}
# use cv to select the correct hyperparameters
# gamma, lambda, subsample, colsample_bytree and min_child_weight are default values

# eta = set to 0.01
# smaller values of shrinkage (almost) always give improved predictive performance
# for 3,000 to 10,000 iterations with shrinkage rates between 0.01 and 0.001.

# tuning for only tree depth and number of rounds
for(depth in 1L:10L){ # tree depth 
  mCV.6 <- xgb.cv(data = Xtrain6, 
                label = Ytrain, 
                params = list(eta=eta, # shrinkage parameter (learning rate) 
                              max_depth=depth), # max number of tree splits/variables in one tree 
                nrounds=10000000, # max number of trees 
                objective = "binary:logistic",
                eval_metric = "logloss",  # evaluation metric
                nfold = 10, # k-folds 
                early_stopping_rounds = 50, # algorithm stops if no more improvement
                verbose = 0) # silent 
  # calculate CVerror and number of rounds for each depth 
  CVerrors6[depth] <- min(mCV.6$evaluation_log$test_logloss_mean) 
  NROUNDS6[depth] <- mCV.6$best_iteration
}
```


```{r}
# select tuning parameters based on best iteration 
best_d6 <- which.min(CVerrors6) # choose depth for lowest cv error
best_nrounds6 <- NROUNDS6[best_d6] # choose nrounds for lowest cv error
```

##### Training the model 

```{r}
# Build the best model based on the cross validation error 
best_model.6 <- xgboost(data = Xtrain6,
             label = Ytrain,
             params = list(eta=eta, 
                           max_depth=best_d6), #tuned
             nrounds=ceiling(best_nrounds6*1.1), # tuned
             objective = "binary:logistic",
             eval_metric = "logloss",
             verbose = 0)
```

```{r}
# Predict based on the best model 
out.6 <- predict(best_model.6, newdata = Xtest6)

# collecting the predictions in a dataframe 
# prediction are the probability of the lead converting into a qualified opportunity (lead conversion rate)
df.out.6 <- data.frame(id=as.integer(rownames(Xtest6)),Prediction_Score6=out.6)
```

#### Demographics+platforms events

```{r}
CVerrors7 <- numeric(10)
NROUNDS7 <- integer(10)
```

```{r}
# set parameter values that will be constant 
eta <- 0.01
```

```{r}
registerDoParallel()
```

```{r}
# use cv to select the correct hyperparameters
# gamma, lambda, subsample, colsample_bytree and min_child_weight are default values

# eta = set to 0.01
# smaller values of shrinkage (almost) always give improved predictive performance
# for 3,000 to 10,000 iterations with shrinkage rates between 0.01 and 0.001.

# tuning for only tree depth and number of rounds
for(depth in 1L:10L){ # tree depth 
  mCV.7 <- xgb.cv(data = Xtrain7, 
                label = Ytrain, 
                params = list(eta=eta, # shrinkage parameter (learning rate) 
                              max_depth=depth), # max number of tree splits/variables in one tree 
                nrounds=10000000, # max number of trees 
                objective = "binary:logistic",
                eval_metric = "logloss",  # evaluation metric
                nfold = 10, # k-folds 
                early_stopping_rounds = 50, # algorithm stops if no more improvement
                verbose = 0) # silent 
  # calculate CVerror and number of rounds for each depth 
  CVerrors7[depth] <- min(mCV.7$evaluation_log$test_logloss_mean) 
  NROUNDS7[depth] <- mCV.7$best_iteration
}
```


```{r}
# select tuning parameters based on best iteration 
best_d7 <- which.min(CVerrors7) # choose depth for lowest cv error
best_nrounds7 <- NROUNDS7[best_d7] # choose nrounds for lowest cv error
```

##### Training the model 

```{r}
# Build the best model based on the cross validation error 
best_model.7 <- xgboost(data = Xtrain7,
             label = Ytrain,
             params = list(eta=eta, 
                           max_depth=best_d7), #tuned
             nrounds=ceiling(best_nrounds7*1.1), # tuned
             objective = "binary:logistic",
             eval_metric = "logloss",
             verbose = 0)
```

```{r}
# Predict based on the best model 
out.7 <- predict(best_model.7, newdata = Xtest7)

# collecting the predictions in a dataframe 
# prediction are the probability of the lead converting into a qualified opportunity (lead conversion rate)
df.out.7 <- data.frame(id=as.integer(rownames(Xtest7)),Prediction_Score7=out.7)
```


#### ROCs 

```{r}
roc_2 <- roc(Ytest, df.out.2$Prediction_Score2)
roc_3 <- roc(Ytest, df.out.3$Prediction_Score3)
roc_4 <- roc(Ytest, df.out.4$Prediction_Score4)
roc_5 <- roc(Ytest, df.out.5$Prediction_Score5)
roc_6 <- roc(Ytest, df.out.6$Prediction_Score6)
roc_7 <- roc(Ytest, df.out.7$Prediction_Score7)
```
```{r}
roc_2$auc
roc_3$auc
roc_4$auc
roc_5$auc
roc_6$auc
roc_7$auc
```


```{r}
#Plot the ROC curve for each model
par(pty = "s")
plot(roc_2,main="ROC Comparison", col="goldenrod")
plot(roc_3, add=TRUE, col="red")
plot(roc_4, add=TRUE, col="cornflowerblue")
plot(roc_5, add=TRUE, col="turquoise")
plot(roc_6, add=TRUE, col="blue")
plot(roc_7, add=TRUE, col="salmon")
textos <- c("D","B","P","DB",
            "BP", "DP")
textos <- paste(textos)
colors <- c("goldenrod","red","cornflowerblue","turquoise", "blue", "salmon")
par(xpd=TRUE)
legend(-0.08,0.6, legend = textos, col = colors, bty="n", cex=1.5, lty=1, lwd=2,
       title="Model")
```




